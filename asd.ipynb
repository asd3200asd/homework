{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Graph is finalized and cannot be modified.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-96c6567ce6ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;31m#Input placeholder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m784\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[0mdrop_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mplaceholder\u001b[1;34m(dtype, shape, name)\u001b[0m\n\u001b[0;32m   1733\u001b[0m                        \"eager execution.\")\n\u001b[0;32m   1734\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1735\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1736\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mplaceholder\u001b[1;34m(dtype, shape, name)\u001b[0m\n\u001b[0;32m   4923\u001b[0m     \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"shape\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4924\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m-> 4925\u001b[1;33m         \"Placeholder\", dtype=dtype, shape=shape, name=name)\n\u001b[0m\u001b[0;32m   4926\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4927\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    452\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m                 instructions)\n\u001b[1;32m--> 454\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    456\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3125\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3127\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_not_finalized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3128\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3129\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_check_not_finalized\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2798\u001b[0m     \"\"\"\n\u001b[0;32m   2799\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_finalized\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Graph is finalized and cannot be modified.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Graph is finalized and cannot be modified."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")\n",
    "\n",
    "#Create Generator\n",
    "def generator(z, reuse=False):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        # initializers\n",
    "        w_init = tf.truncated_normal_initializer(mean=0, stddev=0.02)\n",
    "        b_init = tf.constant_initializer(0.)\n",
    "\n",
    "        # 1st hidden layer\n",
    "        G_w0 = tf.get_variable('G_w0', [100, 256], initializer=w_init)\n",
    "        G_b0 = tf.get_variable('G_b0', [256], initializer=b_init)\n",
    "        G_fc0 = tf.nn.relu(tf.matmul(z, G_w0) + G_b0)\n",
    "\n",
    "        # 2nd hidden layer\n",
    "        G_w1 = tf.get_variable('G_w1', [256, 512], initializer=w_init)\n",
    "        G_b1 = tf.get_variable('G_b1', [512], initializer=b_init)\n",
    "        G_fc1 = tf.nn.relu(tf.matmul(G_fc0, G_w1) + G_b1)\n",
    "\n",
    "        # 3rd hidden layer\n",
    "        G_w2 = tf.get_variable('G_w2', [512, 1024], initializer=w_init)\n",
    "        G_b2 = tf.get_variable('G_b2', [1024], initializer=b_init)\n",
    "        G_fc2 = tf.nn.relu(tf.matmul(G_fc1, G_w2) + G_b2)\n",
    "\n",
    "        # output hidden layer\n",
    "        G_w3 = tf.get_variable('G_w3', [1024, 784], initializer=w_init)\n",
    "        G_b3 = tf.get_variable('G_b3', [784], initializer=b_init)\n",
    "        f_image = tf.nn.tanh(tf.matmul(G_fc2, G_w3) + G_b3)\n",
    "\n",
    "    return f_image\n",
    "\n",
    "# Create discriminator\n",
    "def discriminator(image, drop_out, reuse=False):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        # initializers\n",
    "        w_init = tf.truncated_normal_initializer(mean=0, stddev=0.02)\n",
    "        b_init = tf.constant_initializer(0.)\n",
    "\n",
    "        # 1st hidden layer\n",
    "        D_w0 = tf.get_variable('D_w0', [784, 1024], initializer=w_init)\n",
    "        D_b0 = tf.get_variable('D_b0', [1024], initializer=b_init)\n",
    "        D_fc0 = tf.nn.relu(tf.matmul(image, D_w0) + D_b0)\n",
    "        D_fc0 = tf.nn.dropout(D_fc0, drop_out)\n",
    "\n",
    "        # 2nd hidden layer\n",
    "        D_w1 = tf.get_variable('D_w1', [1024, 512], initializer=w_init)\n",
    "        D_b1 = tf.get_variable('D_b1', [512], initializer=b_init)\n",
    "        D_fc1 = tf.nn.relu(tf.matmul(D_fc0, D_w1) + D_b1)\n",
    "        D_fc1 = tf.nn.dropout(D_fc1, drop_out)\n",
    "\n",
    "        # 3rd hidden layer\n",
    "        D_w2 = tf.get_variable('D_w2', [512, 256], initializer=w_init)\n",
    "        D_b2 = tf.get_variable('D_b2', [256], initializer=b_init)\n",
    "        D_fc2 = tf.nn.relu(tf.matmul(D_fc1, D_w2) + D_b2)\n",
    "        D_fc2 = tf.nn.dropout(D_fc2, drop_out)\n",
    "\n",
    "        # output layer\n",
    "        D_w3 = tf.get_variable('D_w3', [256, 1], initializer=w_init)\n",
    "        D_b3 = tf.get_variable('D_b3', [1], initializer=b_init)\n",
    "        output = tf.sigmoid(tf.matmul(D_fc2, D_w3) + D_b3)\n",
    "\n",
    "        return output\n",
    "\n",
    "# save image\n",
    "def save_f_image(index, z_sample):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(z_sample):  # [i,samples[i]] imax=16\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='gray')\n",
    "    plt.savefig('{}.png'.format(str(index).zfill(3)), bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "#Input placeholder\n",
    "x = tf.placeholder(tf.float32, shape=(None, 784))\n",
    "z = tf.placeholder(tf.float32, shape=(None, 100))\n",
    "drop_out = tf.placeholder(tf.float32)\n",
    "\n",
    "#Generate fake image and discriminate real and fake\n",
    "f_sample = generator(z)\n",
    "D_real = discriminator(x, drop_out)\n",
    "D_fake = discriminator(f_sample,drop_out,reuse=True)\n",
    "\n",
    "#Loss for generator and discriminator\n",
    "D_loss = - tf.reduce_mean(tf.log(D_real) + tf.log(1. -D_fake))\n",
    "G_loss = - tf.reduce_mean(tf.log(D_fake))\n",
    "\"\"\"\n",
    "eps = 1e-2\n",
    "D_loss = tf.reduce_mean(-tf.log(D_real + eps) - tf.log(1 - D_fake + eps))\n",
    "G_loss = tf.reduce_mean(-tf.log(D_fake + eps))\n",
    "\"\"\"\n",
    "#Set Hyper paramatrics\n",
    "batch_size = 100\n",
    "l_rate = 0.0002\n",
    "train_epoch = 200\n",
    "epoch = 0\n",
    "index = 0\n",
    "# trainable variables for each network\n",
    "t_vars = tf.trainable_variables()\n",
    "D_vars = [var for var in t_vars if 'D_' in var.name]\n",
    "G_vars = [var for var in t_vars if 'G_' in var.name]\n",
    "\n",
    "#Optimizer for generator and discriminator\n",
    "D_train =tf.train.AdamOptimizer(l_rate).minimize(D_loss, var_list = D_vars)\n",
    "G_train = tf.train.AdamOptimizer(l_rate).minimize(G_loss, var_list = G_vars)\n",
    "\n",
    "#Setup tensorflow session\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "#nomallize\n",
    "train_set = (mnist.train.images-0.5)/0.5\n",
    "\n",
    "#Default noise\n",
    "test_z = np.random.normal(0, 1, (16, 100))\n",
    "\n",
    "while epoch <= train_epoch:\n",
    "    G_losses =[]\n",
    "    D_losses =[]\n",
    "    #sess.graph.finalize(), for prevent memory explode\n",
    "    \n",
    "    #Save all fake image\n",
    "    if epoch % 1 == 0:\n",
    "        fake_image = sess.run(f_sample, {z: test_z, drop_out: 0.0})\n",
    "        save_f_image(index, fake_image)\n",
    "        index +=1\n",
    "        \n",
    "    #Start training\n",
    "    for i in range(0, train_set.shape[0],batch_size):\n",
    "        sess.graph.finalize()\n",
    "        input_x = train_set[i:i + batch_size]\n",
    "        input_z = np.random.normal(0,1,(batch_size,100))\n",
    "\n",
    "        sess.run(D_train,{x:input_x, z:input_z, drop_out:0.3})\n",
    "        loss_d = sess.run(D_loss,{x:input_x, z:input_z, drop_out:0.3})\n",
    "        D_losses.append(loss_d)\n",
    "\n",
    "        input_z = np.random.normal(0,1,(batch_size,100))\n",
    "\n",
    "        sess.run(G_train, {z: input_z, drop_out: 0.3})\n",
    "        loss_g = sess.run(G_loss, {z: input_z, drop_out: 0.3})\n",
    "        G_losses.append(loss_g)\n",
    "        #print(\"epoch of {}, batch {} ~ {}, D_loss: {}, G_loss: {} \".format(epoch+1,i,i+batch_size,loss_d,loss_g))\n",
    "        #print(\"epoch of {}, batch {} ~ {}, D_loss: {}, G_loss: {} \".format(epoch+1,i,i+batch_size,loss_d,loss_g))\n",
    "    print(\"@epoch of {}, D_loss: {}, G_loss: {}\".format(epoch+1,np.mean(D_losses),np.mean(G_losses)))\n",
    "\n",
    "    epoch += 1\n",
    "\n",
    "#Save model\n",
    "save_path = saver.save(sess, \"/tmp/GAN/GAN_MNIST_200.ckpt\")\n",
    "print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
